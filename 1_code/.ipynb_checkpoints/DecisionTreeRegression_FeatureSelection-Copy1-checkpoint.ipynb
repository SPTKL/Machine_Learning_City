{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender:female_gt_0_5</th>\n",
       "      <th>anxious:agree</th>\n",
       "      <th>anxious:strongly_agree</th>\n",
       "      <th>anxious:disagree</th>\n",
       "      <th>anxious:strongly_disagree</th>\n",
       "      <th>anxious:neither</th>\n",
       "      <th>children:no</th>\n",
       "      <th>children:yes</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_191</th>\n",
       "      <th>Topic_192</th>\n",
       "      <th>Topic_193</th>\n",
       "      <th>Topic_194</th>\n",
       "      <th>Topic_195</th>\n",
       "      <th>Topic_196</th>\n",
       "      <th>Topic_197</th>\n",
       "      <th>Topic_198</th>\n",
       "      <th>Topic_199</th>\n",
       "      <th>Topic_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1103</td>\n",
       "      <td>30.700773</td>\n",
       "      <td>-0.050586</td>\n",
       "      <td>0.113558</td>\n",
       "      <td>0.034757</td>\n",
       "      <td>0.329889</td>\n",
       "      <td>0.221230</td>\n",
       "      <td>0.300567</td>\n",
       "      <td>0.682671</td>\n",
       "      <td>0.317329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143927</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.042804</td>\n",
       "      <td>0.036918</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093098</td>\n",
       "      <td>0.010166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8273</td>\n",
       "      <td>29.817867</td>\n",
       "      <td>0.376868</td>\n",
       "      <td>0.079798</td>\n",
       "      <td>0.030549</td>\n",
       "      <td>0.360824</td>\n",
       "      <td>0.285467</td>\n",
       "      <td>0.243363</td>\n",
       "      <td>0.693130</td>\n",
       "      <td>0.306870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.053710</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.066749</td>\n",
       "      <td>0.007762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9269</td>\n",
       "      <td>31.260406</td>\n",
       "      <td>0.204542</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>0.026907</td>\n",
       "      <td>0.343969</td>\n",
       "      <td>0.273264</td>\n",
       "      <td>0.276351</td>\n",
       "      <td>0.835034</td>\n",
       "      <td>0.164966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.005841</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.071011</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.043345</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10571</td>\n",
       "      <td>33.120257</td>\n",
       "      <td>0.164126</td>\n",
       "      <td>0.093635</td>\n",
       "      <td>0.037560</td>\n",
       "      <td>0.410242</td>\n",
       "      <td>0.185529</td>\n",
       "      <td>0.273034</td>\n",
       "      <td>0.837154</td>\n",
       "      <td>0.162846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.018508</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.024870</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.074610</td>\n",
       "      <td>0.015616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11758</td>\n",
       "      <td>26.284088</td>\n",
       "      <td>-0.066739</td>\n",
       "      <td>0.103949</td>\n",
       "      <td>0.038573</td>\n",
       "      <td>0.239573</td>\n",
       "      <td>0.237358</td>\n",
       "      <td>0.380548</td>\n",
       "      <td>0.741889</td>\n",
       "      <td>0.258111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085206</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>0.015918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        age  gender:female_gt_0_5  anxious:agree  \\\n",
       "0     1103  30.700773             -0.050586       0.113558   \n",
       "1     8273  29.817867              0.376868       0.079798   \n",
       "2     9269  31.260406              0.204542       0.079508   \n",
       "3    10571  33.120257              0.164126       0.093635   \n",
       "4    11758  26.284088             -0.066739       0.103949   \n",
       "\n",
       "   anxious:strongly_agree  anxious:disagree  anxious:strongly_disagree  \\\n",
       "0                0.034757          0.329889                   0.221230   \n",
       "1                0.030549          0.360824                   0.285467   \n",
       "2                0.026907          0.343969                   0.273264   \n",
       "3                0.037560          0.410242                   0.185529   \n",
       "4                0.038573          0.239573                   0.237358   \n",
       "\n",
       "   anxious:neither  children:no  children:yes    ...      Topic_191  \\\n",
       "0         0.300567     0.682671      0.317329    ...       0.143927   \n",
       "1         0.243363     0.693130      0.306870    ...       0.164856   \n",
       "2         0.276351     0.835034      0.164966    ...       0.136182   \n",
       "3         0.273034     0.837154      0.162846    ...       0.128398   \n",
       "4         0.380548     0.741889      0.258111    ...       0.085206   \n",
       "\n",
       "   Topic_192  Topic_193  Topic_194  Topic_195  Topic_196  Topic_197  \\\n",
       "0   0.001070   0.001070   0.006956   0.042804   0.036918   0.019797   \n",
       "1   0.000000   0.001863   0.004967   0.053710   0.009624   0.005278   \n",
       "2   0.000000   0.001230   0.005841   0.014448   0.071011   0.004919   \n",
       "3   0.000000   0.002313   0.018508   0.020821   0.024870   0.010989   \n",
       "4   0.000468   0.001404   0.004682   0.010768   0.020599   0.004682   \n",
       "\n",
       "   Topic_198  Topic_199  Topic_200  \n",
       "0   0.000000   0.093098   0.010166  \n",
       "1   0.000621   0.066749   0.007762  \n",
       "2   0.010452   0.043345   0.008300  \n",
       "3   0.002313   0.074610   0.015616  \n",
       "4   0.001404   0.042603   0.015918  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_demo = pd.read_csv(\"twitter_income.csv\")\n",
    "ds_demo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_demo.columns.get_loc(\"mean_income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Feature Selection(Top 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = ds_demo.loc[:,\"mean_income\"]\n",
    "X = ds_demo.iloc[:,np.r_[1:84, 85:284]]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender:female_gt_0_5</th>\n",
       "      <th>anxious:agree</th>\n",
       "      <th>anxious:strongly_agree</th>\n",
       "      <th>anxious:disagree</th>\n",
       "      <th>anxious:strongly_disagree</th>\n",
       "      <th>anxious:neither</th>\n",
       "      <th>children:no</th>\n",
       "      <th>children:yes</th>\n",
       "      <th>education:degree</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_190</th>\n",
       "      <th>Topic_191</th>\n",
       "      <th>Topic_192</th>\n",
       "      <th>Topic_193</th>\n",
       "      <th>Topic_194</th>\n",
       "      <th>Topic_195</th>\n",
       "      <th>Topic_196</th>\n",
       "      <th>Topic_197</th>\n",
       "      <th>Topic_198</th>\n",
       "      <th>Topic_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>26.189070</td>\n",
       "      <td>0.703617</td>\n",
       "      <td>0.078929</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>0.387177</td>\n",
       "      <td>0.243109</td>\n",
       "      <td>0.257412</td>\n",
       "      <td>0.734602</td>\n",
       "      <td>0.265398</td>\n",
       "      <td>0.328848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012674</td>\n",
       "      <td>0.048532</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.029057</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.057187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>29.070674</td>\n",
       "      <td>0.183706</td>\n",
       "      <td>0.073224</td>\n",
       "      <td>0.025529</td>\n",
       "      <td>0.392168</td>\n",
       "      <td>0.249821</td>\n",
       "      <td>0.259258</td>\n",
       "      <td>0.806966</td>\n",
       "      <td>0.193034</td>\n",
       "      <td>0.404329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.086716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.060886</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>34.020592</td>\n",
       "      <td>0.670030</td>\n",
       "      <td>0.087392</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>0.358172</td>\n",
       "      <td>0.221531</td>\n",
       "      <td>0.308116</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.238710</td>\n",
       "      <td>0.380006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031918</td>\n",
       "      <td>0.123024</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>0.031918</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.066006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>27.239769</td>\n",
       "      <td>0.215531</td>\n",
       "      <td>0.118464</td>\n",
       "      <td>0.028897</td>\n",
       "      <td>0.431512</td>\n",
       "      <td>0.202958</td>\n",
       "      <td>0.218169</td>\n",
       "      <td>0.810287</td>\n",
       "      <td>0.189713</td>\n",
       "      <td>0.270806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020696</td>\n",
       "      <td>0.171214</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.032926</td>\n",
       "      <td>0.019755</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.073377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>26.597661</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>0.091383</td>\n",
       "      <td>0.025606</td>\n",
       "      <td>0.303174</td>\n",
       "      <td>0.254486</td>\n",
       "      <td>0.325351</td>\n",
       "      <td>0.750939</td>\n",
       "      <td>0.249061</td>\n",
       "      <td>0.384895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024715</td>\n",
       "      <td>0.168251</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.062738</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.071293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  gender:female_gt_0_5  anxious:agree  anxious:strongly_agree  \\\n",
       "890   26.189070              0.703617       0.078929                0.033372   \n",
       "2161  29.070674              0.183706       0.073224                0.025529   \n",
       "1889  34.020592              0.670030       0.087392                0.024789   \n",
       "4984  27.239769              0.215531       0.118464                0.028897   \n",
       "3198  26.597661              0.034729       0.091383                0.025606   \n",
       "\n",
       "      anxious:disagree  anxious:strongly_disagree  anxious:neither  \\\n",
       "890           0.387177                   0.243109         0.257412   \n",
       "2161          0.392168                   0.249821         0.259258   \n",
       "1889          0.358172                   0.221531         0.308116   \n",
       "4984          0.431512                   0.202958         0.218169   \n",
       "3198          0.303174                   0.254486         0.325351   \n",
       "\n",
       "      children:no  children:yes  education:degree    ...      Topic_190  \\\n",
       "890      0.734602      0.265398          0.328848    ...       0.012674   \n",
       "2161     0.806966      0.193034          0.404329    ...       0.023985   \n",
       "1889     0.761290      0.238710          0.380006    ...       0.031918   \n",
       "4984     0.810287      0.189713          0.270806    ...       0.020696   \n",
       "3198     0.750939      0.249061          0.384895    ...       0.024715   \n",
       "\n",
       "      Topic_191  Topic_192  Topic_193  Topic_194  Topic_195  Topic_196  \\\n",
       "890    0.048532   0.001236   0.001546   0.002782   0.029057   0.005564   \n",
       "2161   0.086716   0.000000   0.001845   0.016605   0.018450   0.060886   \n",
       "1889   0.123024   0.000930   0.001549   0.008677   0.031918   0.005888   \n",
       "4984   0.171214   0.002822   0.000941   0.000941   0.032926   0.019755   \n",
       "3198   0.168251   0.000951   0.002852   0.006654   0.062738   0.001901   \n",
       "\n",
       "      Topic_197  Topic_198  Topic_199  \n",
       "890    0.007419   0.002473   0.057187  \n",
       "2161   0.012915   0.000000   0.044280  \n",
       "1889   0.007747   0.004958   0.066006  \n",
       "4984   0.004704   0.001881   0.073377  \n",
       "3198   0.004753   0.003802   0.071293  \n",
       "\n",
       "[5 rows x 282 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample accuracy: 1.0\n",
      "Out of sample accuracy: 0.159820282413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# learn model\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# in sample accuracy\n",
    "print ('In sample accuracy:',dt.score(X_train,y_train))\n",
    "\n",
    "# out of sample accuracy\n",
    "print ('Out of sample accuracy:',dt.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample accuracy: 1.0\n",
      "Out of sample accuracy: -0.502385237449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# learn model\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# in sample accuracy\n",
    "print ('In sample accuracy:',dt.score(X_train,y_train))\n",
    "\n",
    "# out of sample accuracy\n",
    "print ('Out of sample accuracy:',dt.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# This time we'll use max_depth to control the complexity of the tree, still using the same train/test split as above,\n",
    "# and optimize the parameter value using GridSearchCV.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth':range(1,11)}\n",
    "dt=DecisionTreeClassifier()\n",
    "gr=GridSearchCV(dt,param_grid=param_grid)\n",
    "rs=gr.fit(X_train,y_train)\n",
    "print (rs.best_params_)\n",
    "# print (roc_auc_score(np.array(y_test),rs.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=8)\n",
    "dt.fit(X_train, y_train)\n",
    "Feature_importance=pd.DataFrame([list(X_train.columns),list(dt.feature_importances_)]).T\n",
    "Feature_importance.columns=[\"variables\",\"importance\"]\n",
    "\n",
    "# list the top 5 most important features in order\n",
    "df_select = Feature_importance.sort_values(by=\"importance\",ascending=False).iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Topic_124</td>\n",
       "      <td>0.0673911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Topic_163</td>\n",
       "      <td>0.0556497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Topic_29</td>\n",
       "      <td>0.0483988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Topic_116</td>\n",
       "      <td>0.0439774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Topic_105</td>\n",
       "      <td>0.0422885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Topic_145</td>\n",
       "      <td>0.0405308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Topic_173</td>\n",
       "      <td>0.0399084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Topic_107</td>\n",
       "      <td>0.0389329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>listed</td>\n",
       "      <td>0.0380436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Topic_100</td>\n",
       "      <td>0.0330904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Topic_158</td>\n",
       "      <td>0.0246853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Topic_153</td>\n",
       "      <td>0.0237152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Topic_40</td>\n",
       "      <td>0.0222939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Topic_69</td>\n",
       "      <td>0.0218793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Topic_48</td>\n",
       "      <td>0.0196289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Topic_160</td>\n",
       "      <td>0.0193804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Topic_12</td>\n",
       "      <td>0.0190163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Topic_2</td>\n",
       "      <td>0.0170266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Topic_156</td>\n",
       "      <td>0.0150414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Topic_189</td>\n",
       "      <td>0.0143253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variables importance\n",
       "206  Topic_124  0.0673911\n",
       "245  Topic_163  0.0556497\n",
       "111   Topic_29  0.0483988\n",
       "198  Topic_116  0.0439774\n",
       "187  Topic_105  0.0422885\n",
       "227  Topic_145  0.0405308\n",
       "255  Topic_173  0.0399084\n",
       "189  Topic_107  0.0389329\n",
       "67      listed  0.0380436\n",
       "182  Topic_100  0.0330904\n",
       "240  Topic_158  0.0246853\n",
       "235  Topic_153  0.0237152\n",
       "122   Topic_40  0.0222939\n",
       "151   Topic_69  0.0218793\n",
       "130   Topic_48  0.0196289\n",
       "242  Topic_160  0.0193804\n",
       "94    Topic_12  0.0190163\n",
       "84     Topic_2  0.0170266\n",
       "238  Topic_156  0.0150414\n",
       "271  Topic_189  0.0143253"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20 = list(df_select.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic_124',\n",
       " 'Topic_163',\n",
       " 'Topic_29',\n",
       " 'Topic_116',\n",
       " 'Topic_105',\n",
       " 'Topic_145',\n",
       " 'Topic_173',\n",
       " 'Topic_107',\n",
       " 'listed',\n",
       " 'Topic_100',\n",
       " 'Topic_158',\n",
       " 'Topic_153',\n",
       " 'Topic_40',\n",
       " 'Topic_69',\n",
       " 'Topic_48',\n",
       " 'Topic_160',\n",
       " 'Topic_12',\n",
       " 'Topic_2',\n",
       " 'Topic_156',\n",
       " 'Topic_189']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
